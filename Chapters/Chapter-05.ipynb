{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Chapter 05: Untitled__\n",
    "---\n",
    "by Daniel Weller & Holger Mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.packages <- c(\"bigmemory\", \"data.table\", \"rgdal\", \"rgeos\")\n",
    "lapply(data.packages, require, character.only=T); rm(data.packages)\n",
    "\n",
    "stat.packages <- c(\"bivariate\", \"extRemes\", \"ks\", \"mev\", \"mvtnorm\")\n",
    "lapply(stat.packages, require, character.only=T); rm(stat.packages)\n",
    "\n",
    "if(.Platform$OS.type!=\"windows\"){\n",
    "  paths <- c(\"/Volumes/Climate Rasters/\", \"/Volumes/Analysis Storage\", \"~/GitHub/Report/\")} else {\n",
    "    paths <- c(\"D:/Climate Rasters/\", \"E:/Analysis Storage/\", \"C:/Users/Cloud/GitHub/Report/\")}\n",
    "setwd(paths[3]); options(scipen=10); set.seed(12345); setDTthreads(16)\n",
    "rasterOptions(progress=\"text\", maxmemory=1e+09, chunksize=1e+08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn.years <- seq(10, 50, by=10); heat.rank <- c(0, 50, 100, 155, 225, 300, 400, 525, 700, 875)/1000\n",
    "cold.times <- big.matrix(nrow=cells, ncol=length(rtn.years), init=NULL, separated=FALSE,\n",
    "                         backingpath=\".\", backingfile=\"Cold_Times_Back\", descriptorfile=\"Cold_Times_Desc\")\n",
    "\n",
    "for(i in 1:length(cold.rank)){\n",
    "  for(j in cell.list){\n",
    "    values <- fread(paste(paths[2], \"Cold Wave Large/Cell \", j, \".csv\",sep=\"\"))\n",
    "    values <- values[, Rise := round(Thresh, digits=2) - MaxDay][WaveID >= 1]\n",
    "    values[, `:=`(Excess=sum(round(Rise, digits=2)), Length=max(DaysCount, na.rm=TRUE)), by=.(Year, WaveID)]\n",
    "    values <- unique(values[, .(Year, WaveID, Excess, Length)])[Excess >= 0.03 & Length >= 3]\n",
    "    for(k in 1:nrow(values)){values[k, Prob := cold.fun(values[k,3], values[k,4])]}\n",
    "    values <- values[Prob >= cold.rank[i]][, .(Year, Excess, Length)]\n",
    "    values[, `:=`(Row=seq_len(.N)), by=.(Year)]; counts <- max(values[, .(Row)])\n",
    "    values <- values[CJ(Year=1979:2019, Row=1:counts, unique=TRUE), on=.(Year, Row)]\n",
    "    setnafill(values, fill=0, cols=c(\"Excess\", \"Length\"))\n",
    "    try(precs <- NC.diag(values$Length, u=seq(0, quantile(values$Length, probs=0.99), by=1), size=0.1))\n",
    "    try(which <- min(which(precs$e.p.values > 0.1)))\n",
    "    try(thrsh <- precs$u[which])\n",
    "    try(if(is.na(thrsh)){thrsh <- 0})\n",
    "    try(clust <- decluster(values$Length, threshold=thrsh, method=\"runs\"))\n",
    "    try(model <- fevd(clust, threshold=thrsh, type=\"GP\", span=years))\n",
    "    ifelse(exists(\"model\"), cold.times[j,] <- return.level(model, rtn.years)[1:5], cold.times[j,] <- 0)\n",
    "    try(rm(precs, which, thrsh, clust, model, values), silent=TRUE)\n",
    "    cat(paste(\"Current Cell:\", j, \"in\", i, \"\\n\", seq=\"\"))\n",
    "    if(j%in%seq(1, cells, by=1e+2)){invisible(gc())}}\n",
    "  write.big.matrix(cold.times, paste(\"./Cold_Wave_Times_\", i,\".csv\", sep=\"\")); cold.times <- NA}\n",
    "\n",
    "\n",
    "heat.times <- big.matrix(nrow=cells, ncol=length(rtn.years), init=NULL, separated=FALSE,\n",
    "                         backingpath=\".\", backingfile=\"Heat_Times_Back\", descriptorfile=\"Heat_Times_Desc\")\n",
    "\n",
    "for(i in 1:length(heat.rank)){\n",
    "  for(j in cell.list){\n",
    "    values <- fread(paste(paths[2], \"Heat Wave Large/Cell \", j, \".csv\",sep=\"\"))\n",
    "    values <- values[, Rise := MaxDay - round(Thresh, digits=2)][WaveID >= 1]\n",
    "    values[, `:=`(Excess=sum(round(Rise, digits=2)), Length=max(DaysCount, na.rm=TRUE)), by=.(Year, WaveID)]\n",
    "    values <- unique(values[, .(Year, WaveID, Excess, Length)])[Excess >= 0.03 & Length >= 3]\n",
    "    for(k in 1:nrow(values)){values[k, Prob := heat.fun(values[k,3], values[k,4])]}\n",
    "    values <- values[Prob >= heat.rank[i]][, .(Year, Excess, Length)]\n",
    "    values[, `:=`(Row=seq_len(.N)), by=.(Year)]; counts <- max(values[, .(Row)])\n",
    "    values <- values[CJ(Year=1979:2019, Row=1:counts, unique=TRUE), on=.(Year, Row)]\n",
    "    setnafill(values, fill=0, cols=c(\"Excess\", \"Length\"))\n",
    "    try(precs <- NC.diag(values$Length, u=seq(0, quantile(values$Length, probs=0.99), by=1), size=0.1))\n",
    "    try(which <- min(which(precs$e.p.values > 0.1)))\n",
    "    try(thrsh <- precs$u[which])\n",
    "    try(if(is.na(thrsh)){thrsh <- 0})\n",
    "    try(clust <- decluster(values$Length, threshold=thrsh, method=\"runs\"))\n",
    "    try(model <- fevd(clust, threshold=thrsh, type=\"GP\", span=years))\n",
    "    ifelse(exists(\"model\"), heat.times[j,] <- return.level(model, rtn.years)[1:5], heat.times[j,] <- 0)\n",
    "    try(rm(precs, which, thrsh, clust, model, values), silent=TRUE)\n",
    "    cat(paste(\"Current Cell:\", j, \"in\", i, \"\\n\", seq=\"\"))\n",
    "    if(j%in%seq(1, cells, by=1e+2)){invisible(gc())}}\n",
    "  write.big.matrix(heat.times, paste(\"./Heat_Wave_Times_\", i,\".csv\", sep=\"\")); heat.times[,] <- NA)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
